{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914\n"
     ]
    }
   ],
   "source": [
    "# first few tagged sentences\n",
    "print(len(nltk_data))\n",
    "#print(nltk_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test into 95:5 ratio\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "#print(train_set[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95593"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NOUN': 27424,\n",
       "         '.': 11111,\n",
       "         'ADP': 9363,\n",
       "         'DET': 8291,\n",
       "         'ADJ': 6064,\n",
       "         'PRT': 3061,\n",
       "         'VERB': 12888,\n",
       "         'X': 6267,\n",
       "         'PRON': 2601,\n",
       "         'NUM': 3364,\n",
       "         'ADV': 3018,\n",
       "         'CONJ': 2141})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which is the most frequent tag in the corpus,frequency of elements in a list, the Counter() class from collections\n",
    "from collections import Counter\n",
    "\n",
    "tags = [pair[1] for pair in train_tagged_words]\n",
    "tag_counts = Counter(tags)\n",
    "tag_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which word is most commonly assigned to the tag X\n",
    "#x_tags = [pair for pair in train_tagged_words if pair[1].lower() == 'x']\n",
    "#x_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('away', 'PRT'),\n",
       " ('over', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('To', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('on', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('over', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('back', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('down', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('To', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('around', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('about', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('down', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('in', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('down', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('down', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('down', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('around', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('on', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('about', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('over', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('together', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('back', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('for', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('down', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('off', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('out', 'PRT'),\n",
       " ('To', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('up', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " (\"'s\", 'PRT'),\n",
       " (\"'\", 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ('to', 'PRT'),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which word is most commonly assigned to the tag X\n",
    "prt_tags = [pair for pair in train_tagged_words if pair[1] == 'PRT']\n",
    "prt_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['INGERSOLL-RAND',\n",
       " 'Co',\n",
       " '.',\n",
       " '-LRB-',\n",
       " 'Woodcliff',\n",
       " 'Lake',\n",
       " ',',\n",
       " 'N.J',\n",
       " '.',\n",
       " '-RRB-']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12056\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "train_vocabulary_set = set(tokens)\n",
    "print(len(train_vocabulary_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "tag_set = set([pair[1] for pair in train_tagged_words])\n",
    "len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.', 'PRON', 'ADJ', 'PRT', 'ADP', 'CONJ', 'ADV', 'VERB', 'X', 'NUM', 'DET', 'NOUN'}\n"
     ]
    }
   ],
   "source": [
    "print(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(tag_set)\n",
    "v = len(train_vocabulary_set)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)\n",
    "\n",
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)\n",
    "\n",
    "#Heatmap \n",
    "def plotheatmap(df,Title,Figsize=None):\n",
    "    \n",
    "    f,ax= plt.subplots(1,1,figsize=Figsize)   \n",
    "    sns.heatmap(df,annot=True)\n",
    "    ax.set_title(Title)\n",
    "    \n",
    "    #Fix 3.11 matplot version issue by setting the limits manually.\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tag_set), len(tag_set)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tag_set)):\n",
    "    for j, t2 in enumerate(list(tag_set)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tags_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tag_set), index=list(tag_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>ADP</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>X</th>\n",
       "      <th>NUM</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>0.065791</td>\n",
       "      <td>0.043920</td>\n",
       "      <td>0.002520</td>\n",
       "      <td>0.091711</td>\n",
       "      <td>0.058051</td>\n",
       "      <td>0.052291</td>\n",
       "      <td>0.087931</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.080281</td>\n",
       "      <td>0.172712</td>\n",
       "      <td>0.223562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRON</td>\n",
       "      <td>0.041522</td>\n",
       "      <td>0.007689</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.012687</td>\n",
       "      <td>0.021915</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.034218</td>\n",
       "      <td>0.485198</td>\n",
       "      <td>0.093426</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.209150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.065139</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.066623</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>0.077836</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.012038</td>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.021108</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.698384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PRT</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.017315</td>\n",
       "      <td>0.084613</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.020908</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.009474</td>\n",
       "      <td>0.402483</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>0.057824</td>\n",
       "      <td>0.101601</td>\n",
       "      <td>0.245018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADP</td>\n",
       "      <td>0.038342</td>\n",
       "      <td>0.068888</td>\n",
       "      <td>0.107337</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.017089</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.013137</td>\n",
       "      <td>0.008224</td>\n",
       "      <td>0.034284</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.326818</td>\n",
       "      <td>0.320837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CONJ</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.061186</td>\n",
       "      <td>0.119103</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.053713</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.054180</td>\n",
       "      <td>0.154601</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.040635</td>\n",
       "      <td>0.119570</td>\n",
       "      <td>0.347034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ADV</td>\n",
       "      <td>0.134195</td>\n",
       "      <td>0.015242</td>\n",
       "      <td>0.128893</td>\n",
       "      <td>0.013917</td>\n",
       "      <td>0.121604</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.080186</td>\n",
       "      <td>0.344930</td>\n",
       "      <td>0.022863</td>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.068588</td>\n",
       "      <td>0.031146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>VERB</td>\n",
       "      <td>0.034373</td>\n",
       "      <td>0.035692</td>\n",
       "      <td>0.065410</td>\n",
       "      <td>0.031425</td>\n",
       "      <td>0.090549</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.082790</td>\n",
       "      <td>0.169770</td>\n",
       "      <td>0.217955</td>\n",
       "      <td>0.023045</td>\n",
       "      <td>0.133302</td>\n",
       "      <td>0.110335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>X</td>\n",
       "      <td>0.163396</td>\n",
       "      <td>0.055529</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.185575</td>\n",
       "      <td>0.143609</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.026169</td>\n",
       "      <td>0.205042</td>\n",
       "      <td>0.074198</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.054731</td>\n",
       "      <td>0.061433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NUM</td>\n",
       "      <td>0.117717</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.033591</td>\n",
       "      <td>0.027943</td>\n",
       "      <td>0.035375</td>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.208680</td>\n",
       "      <td>0.183413</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.352556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DET</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.202991</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.012061</td>\n",
       "      <td>0.039320</td>\n",
       "      <td>0.045712</td>\n",
       "      <td>0.022072</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.640815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.239826</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.043794</td>\n",
       "      <td>0.176634</td>\n",
       "      <td>0.042372</td>\n",
       "      <td>0.017102</td>\n",
       "      <td>0.147061</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.264841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .      PRON       ADJ       PRT       ADP      CONJ       ADV  \\\n",
       ".     0.094141  0.065791  0.043920  0.002520  0.091711  0.058051  0.052291   \n",
       "PRON  0.041522  0.007689  0.072664  0.012687  0.021915  0.004614  0.034218   \n",
       "ADJ   0.065139  0.000495  0.066623  0.010389  0.077836  0.016821  0.004617   \n",
       "PRT   0.043450  0.017315  0.084613  0.001960  0.020908  0.002287  0.009474   \n",
       "ADP   0.038342  0.068888  0.107337  0.001388  0.017089  0.000641  0.013137   \n",
       "CONJ  0.035965  0.061186  0.119103  0.005138  0.053713  0.000467  0.054180   \n",
       "ADV   0.134195  0.015242  0.128893  0.013917  0.121604  0.007290  0.080186   \n",
       "VERB  0.034373  0.035692  0.065410  0.031425  0.090549  0.005354  0.082790   \n",
       "X     0.163396  0.055529  0.017393  0.185575  0.143609  0.010212  0.026169   \n",
       "NUM   0.117717  0.001486  0.033591  0.027943  0.035375  0.013971  0.002973   \n",
       "DET   0.017851  0.003618  0.202991  0.000241  0.009528  0.000482  0.012061   \n",
       "NOUN  0.239826  0.004704  0.011924  0.043794  0.176634  0.042372  0.017102   \n",
       "\n",
       "          VERB         X       NUM       DET      NOUN  \n",
       ".     0.087931  0.027000  0.080281  0.172712  0.223562  \n",
       "PRON  0.485198  0.093426  0.006920  0.009996  0.209150  \n",
       "ADJ   0.012038  0.021603  0.021108  0.004947  0.698384  \n",
       "PRT   0.402483  0.013068  0.057824  0.101601  0.245018  \n",
       "ADP   0.008224  0.034284  0.063014  0.326818  0.320837  \n",
       "CONJ  0.154601  0.008407  0.040635  0.119570  0.347034  \n",
       "ADV   0.344930  0.022863  0.031146  0.068588  0.031146  \n",
       "VERB  0.169770  0.217955  0.023045  0.133302  0.110335  \n",
       "X     0.205042  0.074198  0.002713  0.054731  0.061433  \n",
       "NUM   0.018728  0.208680  0.183413  0.003567  0.352556  \n",
       "DET   0.039320  0.045712  0.022072  0.005307  0.640815  \n",
       "NOUN  0.147061  0.028807  0.009627  0.013310  0.264841  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# frequent tags\n",
    "# filter the df to get P(t2, t1) > 0.35\n",
    "tags_frequent = tags_df[tags_df>0.35]\n",
    "plotheatmap(tags_frequent,\"corrleation of Tags\",Figsize=(12, 6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 69, 23, 105, 69]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running on entire test dataset would take more than 3-4hrs. \n",
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "#test_run\n",
    "rndom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 10, 98, 138, 144]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "rndom\n",
    "\n",
    "#[9, 172, 178, 22, 26]\n",
    "#[91, 61, 5, 8, 5]\n",
    "#[113, 30, 2, 24, 150]   - 98.3\n",
    "#[88, 68, 15, 149, 106]  - 91.6\n",
    "#[38, 118, 117, 45, 181] - 88.24, 89.8\n",
    "#[104, 98, 52, 154, 46] - 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_Vanilla(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to check accuracy\n",
    "def check_accuracy(tagged_set, test_run_base,msg):\n",
    "    check = [i for i, j in zip(tagged_set, test_run_base) if i == j] \n",
    "    accuracy = round((len(check)/len(tagged_set))*100,2)\n",
    "    print(msg,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  53.11\n",
      "Accuracy of Viterbi Vanilla model:  88.67\n"
     ]
    }
   ],
   "source": [
    "#Test on Vanilla Viterbi model\n",
    "start = time.time()\n",
    "tagged_set1 = Viterbi_Vanilla(test_tagged_words)\n",
    "end = time.time()\n",
    "print(\"Time taken in seconds: \", round(end-start,2))\n",
    "check_accuracy(tagged_set1,test_run_base,'Accuracy of Viterbi Vanilla model: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tagged_seq)\n",
    "#print(test_run_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('to', 'PRT'), (('position', 'NOUN'), ('position', 'VERB'))],\n",
       " [('failed', 'VERB'),\n",
       "  (('labor-management', 'ADJ'), ('labor-management', 'NOUN'))],\n",
       " [('was', 'VERB'), (('kind', 'NOUN'), ('kind', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('playful', '.'), ('playful', 'ADJ'))],\n",
       " [('was', 'VERB'), (('dreadful', '.'), ('dreadful', 'ADJ'))],\n",
       " [('her', 'PRON'), (('war-damaged', '.'), ('war-damaged', 'ADJ'))],\n",
       " [('her', 'PRON'), (('lover', '.'), ('lover', 'NOUN'))],\n",
       " [('indicators', 'NOUN'), (('gauges', '.'), ('gauges', 'VERB'))],\n",
       " [('a', 'DET'), (('worsening', '.'), ('worsening', 'NOUN'))],\n",
       " [('*U*', 'X'), (('write-off', '.'), ('write-off', 'NOUN'))],\n",
       " [('capitalized', 'VERB'), (('servicing', 'VERB'), ('servicing', 'NOUN'))],\n",
       " [('home', 'NOUN'), (('financing', 'NOUN'), ('financing', 'VERB'))],\n",
       " [('was', 'VERB'), (('kind', 'NOUN'), ('kind', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('playful', '.'), ('playful', 'ADJ'))],\n",
       " [('was', 'VERB'), (('dreadful', '.'), ('dreadful', 'ADJ'))],\n",
       " [('her', 'PRON'), (('war-damaged', '.'), ('war-damaged', 'ADJ'))],\n",
       " [('her', 'PRON'), (('lover', '.'), ('lover', 'NOUN'))]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_set1, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* All unknown numbers are tagged as ADJ instead of NUM\n",
    "* All unknown words are tagged as ADJ since its the first tag. \n",
    "* As heat map suggests most of the DET is followed by NOUN, hence we can add this rule to Vanilla viterbi logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unknown words : 91\n",
      "\n",
      "\n",
      "Unknown Words : ['*T*-1', '0', 'been', 'position', 'playful', 'said', ';', 'capitalized', \"'s\", 'is', 'help', 'which', 'million', 'financing', 'and', 'write-off', 'she', 'into', 'mobile', 'to', 'was', '$', 'at', 'subsidiary', 'as', 'Stephen', 'brought', 'number', 'Steinberg', 'difference', 'himself', 'friendly', 'lover', 'husband', 'gauges', 'Wolf', 'reporting', 'their', 'Although', 'on', 'who', 'UAL', 'drain', 'home', 'could', 'children', 'investment', 'openly', 'survey', '*-2', 'her', 'earnings', 'worsening', 'a', ',', 'revive', 'Mr.', '.', 'Each', 'bid', 'investor', 'labor-management', '*U*', 'war-damaged', 'big', 'between', 'improvement', 'may', 'the', '62', 'dreadful', 'be', 'bulk', 'in', 'particular', 'kind', 'The', 'banker', 'indicators', 'charge', 'of', 'failed', 'trying', 'purchasers', 'pretax', 'servicing', 'had', 'One', 'Chairman', 'area', 'company']\n"
     ]
    }
   ],
   "source": [
    "# list all unknown words in test set compared to train set.\n",
    "\n",
    "test_tagged_set = set([t for t in test_tagged_words])\n",
    "train_tagged_set = set([t for t in train_tagged_words])\n",
    "\n",
    "unknown_words = list(test_tagged_set - train_tagged_set)\n",
    "print(\"Total Unknown words :\", len(unknown_words))\n",
    "print(\"\\n\")\n",
    "print(\"Unknown Words :\", unknown_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification of vanilla Viterbi Heuristic algorithm.\n",
    "def Viterbi_m1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            \n",
    "            # modification to the original vanilla viterbi algorithm \n",
    "            # If word in unknown then consider only the transition_p \n",
    "            \n",
    "            if word not in train_vocabulary_set:\n",
    "                state_probability = transition_p\n",
    "            else:\n",
    "                state_probability = emission_p * transition_p\n",
    "            \n",
    "            \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  51.27\n",
      "Accuracy of Modified Viterbi model:  89.33\n"
     ]
    }
   ],
   "source": [
    "#Test on modified Viterbi model\n",
    "start = time.time()\n",
    "tagged_set2 = Viterbi_m1(test_tagged_words)\n",
    "end = time.time()\n",
    "print(\"Time taken in seconds: \", round(end-start,2))\n",
    "check_accuracy(tagged_set2,test_run_base,'Accuracy of Modified Viterbi model: ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('to', 'PRT'), (('position', 'NOUN'), ('position', 'VERB'))],\n",
       " [('failed', 'VERB'),\n",
       "  (('labor-management', 'ADJ'), ('labor-management', 'NOUN'))],\n",
       " [('was', 'VERB'), (('kind', 'NOUN'), ('kind', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('playful', 'NOUN'), ('playful', 'ADJ'))],\n",
       " [('was', 'VERB'), (('dreadful', 'X'), ('dreadful', 'ADJ'))],\n",
       " [('her', 'PRON'), (('war-damaged', 'VERB'), ('war-damaged', 'ADJ'))],\n",
       " [('her', 'PRON'), (('lover', 'VERB'), ('lover', 'NOUN'))],\n",
       " [('indicators', 'NOUN'), (('gauges', 'NOUN'), ('gauges', 'VERB'))],\n",
       " [('*U*', 'X'), (('write-off', 'VERB'), ('write-off', 'NOUN'))],\n",
       " [('capitalized', 'VERB'), (('servicing', 'VERB'), ('servicing', 'NOUN'))],\n",
       " [('home', 'NOUN'), (('financing', 'NOUN'), ('financing', 'VERB'))],\n",
       " [('was', 'VERB'), (('kind', 'NOUN'), ('kind', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('playful', 'NOUN'), ('playful', 'ADJ'))],\n",
       " [('was', 'VERB'), (('dreadful', 'X'), ('dreadful', 'ADJ'))],\n",
       " [('her', 'PRON'), (('war-damaged', 'VERB'), ('war-damaged', 'ADJ'))],\n",
       " [('her', 'PRON'), (('lover', 'VERB'), ('lover', 'NOUN'))]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_set2, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'[0-9].?[,\\/]?[0-9]*','NUM')# Numbers \n",
    "    ]\n",
    "\n",
    "# rule based RegexpTagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification of Viterbi Heuristic algorithm to include \n",
    "def Viterbi_m2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        num_word=re.search('^[0-9]*.?[0-9]*[0-9]$',word)\n",
    "        \n",
    "        if num_word and word not in train_vocabulary_set:\n",
    "            state.append('NUM')\n",
    "        else:\n",
    "            for tag in T:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "                # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            \n",
    "                # modification to the original vanilla viterbi algorithm \n",
    "                # If word in unknown then consider only the transition_p \n",
    "            \n",
    "                if word not in train_vocabulary_set:\n",
    "                \n",
    "                    state_probability = transition_p\n",
    "                else:\n",
    "                    state_probability = emission_p * transition_p\n",
    "            \n",
    "            \n",
    "                p.append(state_probability)\n",
    "            \n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = T[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  51.5\n",
      "Accuracy of Modified Viterbi Model 2:  89.33\n"
     ]
    }
   ],
   "source": [
    "#Test on modified Viterbi model\n",
    "start = time.time()\n",
    "tagged_set3 = Viterbi_m2(test_tagged_words)\n",
    "end = time.time()\n",
    "print(\"Time taken in seconds: \", round(end-start,2))\n",
    "check_accuracy(tagged_set3,test_run_base,'Accuracy of Modified Viterbi Model 2: ')\n",
    "\n",
    " tagging the test sentences\n",
    "viterbi_trigram_tagged_seq = viterbi_backedup_by_trigram_tagger(test_tagged_words)\n",
    "# accuracy\n",
    "viterbi_trigram_word_check = [i for i, j in zip(viterbi_trigram_tagged_seq, test_run_base) if i == j]\n",
    "viterbi_trigram_accuracy = len(viterbi_trigram_word_check)/len(viterbi_trigram_tagged_seq)#\n",
    "\n",
    "print(\"The accuracy of the viterbi_backedup_by_trigram_tagger is -\", viterbi_trigram_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('to', 'PRT'), (('position', 'NOUN'), ('position', 'VERB'))],\n",
       " [('failed', 'VERB'),\n",
       "  (('labor-management', 'ADJ'), ('labor-management', 'NOUN'))],\n",
       " [('was', 'VERB'), (('kind', 'NOUN'), ('kind', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('playful', 'NOUN'), ('playful', 'ADJ'))],\n",
       " [('was', 'VERB'), (('dreadful', 'X'), ('dreadful', 'ADJ'))],\n",
       " [('her', 'PRON'), (('war-damaged', 'VERB'), ('war-damaged', 'ADJ'))],\n",
       " [('her', 'PRON'), (('lover', 'VERB'), ('lover', 'NOUN'))],\n",
       " [('indicators', 'NOUN'), (('gauges', 'NOUN'), ('gauges', 'VERB'))],\n",
       " [('*U*', 'X'), (('write-off', 'VERB'), ('write-off', 'NOUN'))],\n",
       " [('capitalized', 'VERB'), (('servicing', 'VERB'), ('servicing', 'NOUN'))],\n",
       " [('home', 'NOUN'), (('financing', 'NOUN'), ('financing', 'VERB'))],\n",
       " [('was', 'VERB'), (('kind', 'NOUN'), ('kind', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('playful', 'NOUN'), ('playful', 'ADJ'))],\n",
       " [('was', 'VERB'), (('dreadful', 'X'), ('dreadful', 'ADJ'))],\n",
       " [('her', 'PRON'), (('war-damaged', 'VERB'), ('war-damaged', 'ADJ'))],\n",
       " [('her', 'PRON'), (('lover', 'VERB'), ('lover', 'NOUN'))]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_set3, test_run_base)) if j[0]!=j[1]]\n",
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Unigram Tagger is - 0.8998622860515444\n"
     ]
    }
   ],
   "source": [
    "# Unigram Tagger\n",
    "\n",
    "unigram_tagger = nltk.UnigramTagger(train_set)\n",
    "unigram_tagger_accuracy = unigram_tagger.evaluate(test_set)\n",
    "print(\"The accuracy of the Unigram Tagger is -\", unigram_tagger_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patterns for tagging using a rule based regex tagger -\n",
    "\n",
    "patterns = [\n",
    "    (r'^[aA-zZ].*[0-9]+','NOUN'),  # Alpha Numeric\n",
    "    (r'.*ness$', 'NOUN'),\n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'.*', 'NOUN'),    \n",
    "    (r'.*ly$', 'ADV'),\n",
    "    (r'^(0|([*|-|$].*))','X'), # Any special character combination\n",
    "    (r'.*ould$', 'X'), # modals\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),\n",
    "    (r'^([0-9]|[aA-zZ])+\\-[aA-zZ]*$','ADJ'),\n",
    "    (r'.*able$', 'ADJ'), # adjective like 100-megabytes 237-Seats\n",
    "    (r'[aA-zZ]+(ed|ing|es)$', 'VERB'), # Any word ending with 'ing' or 'ed' is a verb\n",
    "    (r'[0-9].?[,\\/]?[0-9]*','NUM')# Numbers \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Unigram Tagger backed up by the RegexpTagger is - 0.908715325595121\n"
     ]
    }
   ],
   "source": [
    "# rule based RegexpTagger\n",
    "\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)\n",
    "\n",
    "# unigram tagger backed up by the rule-based tagger\n",
    "rule_based_unigram_tagger = nltk.UnigramTagger(train_set, backoff = rule_based_tagger)\n",
    "\n",
    "accuracy_rule_based_unigram_tagger = rule_based_unigram_tagger.evaluate(test_set)\n",
    "\n",
    "print(\"The accuracy of the Unigram Tagger backed up by the RegexpTagger is -\", accuracy_rule_based_unigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Bigram Tagger backed up by the rule_based_unigram_tagger is - 0.9118630729883926\n"
     ]
    }
   ],
   "source": [
    "# Bigram tagger\n",
    "\n",
    "bigram_tagger = nltk.BigramTagger(train_set, backoff = rule_based_unigram_tagger)\n",
    "bigram_tagger.evaluate(test_set)\n",
    "accuracy_bigram_tagger = bigram_tagger.evaluate(test_set)\n",
    "print(\"The accuracy of the Bigram Tagger backed up by the rule_based_unigram_tagger is -\", accuracy_bigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Trigram Tagger backed up by the bigram_tagger is - 0.9120598072004722\n"
     ]
    }
   ],
   "source": [
    "# trigram tagger\n",
    "\n",
    "trigram_tagger = nltk.TrigramTagger(train_set, backoff = bigram_tagger)\n",
    "trigram_tagger.evaluate(test_set)\n",
    "accuracy_trigram_tagger = trigram_tagger.evaluate(test_set)\n",
    "print(\"The accuracy of the Trigram Tagger backed up by the bigram_tagger is -\", accuracy_trigram_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_tagger(word, train_set = train_set):\n",
    "    patterns = [\n",
    "    (r'[aA-zZ]+(ed|ing|es)$', 'VERB'), # Any word ending with 'ing' or 'ed' is a verb\n",
    "\n",
    "    (r'.*ly$', 'ADV'),\n",
    "        \n",
    "    (r'^([0-9]|[aA-zZ])+\\-[aA-zZ]*$','ADJ'),\n",
    "    (r'.*able$', 'ADJ'), \n",
    "    (r'.*ful$', 'ADJ'),\n",
    "    (r'.*ous$', 'ADJ'),\n",
    "        \n",
    "    (r'^[aA-zZ].*[0-9]+','NOUN'),     # Alpha Numeric\n",
    "    (r'.*ness$', 'NOUN'),\n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns - words ending with 's\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'.*ers$', 'NOUN'),              # eg.- kinderganteners, autobioghapgers\n",
    "    (r'.*ment$', 'NOUN'),\n",
    "    (r'.*town$', 'NOUN'),\n",
    "        \n",
    "    (r'^(0|([*|-|$].*))','X'), # Any special character combination\n",
    "    (r'.*ould$', 'X'),\n",
    "        \n",
    "    (r'(The|the|A|a|An|an|That|that|This|this|Those|those|These|these)$', 'DET'), # That/this/these/those belong to the category of Demonstrative determiners\n",
    "    (r'[0-9].?[,\\/]?[0-9]*','NUM'), # Numbers \n",
    "        \n",
    "    (r'.*', 'NOUN')\n",
    "    ]\n",
    "\n",
    "    regex_based_tagger = nltk.RegexpTagger(patterns)\n",
    "    # trigram backed up by the regex tagger\n",
    "    trigram_regex_tagger = nltk.TrigramTagger(train_set, backoff = regex_based_tagger)\n",
    "    return trigram_regex_tagger.tag_sents([[(word)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_backedup_by_trigram_tagger(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    tag_set = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    # use the trigram tagger backed up by the rule based tagger\n",
    "    # for unknown words.\n",
    "    for key, word in enumerate(words):\n",
    "        if word not in train_vocabulary_set:\n",
    "            unknown_word_tag = trigram_tagger(word)\n",
    "            for sent in unknown_word_tag:\n",
    "                for tup in sent:\n",
    "                    state.append(tup[1])\n",
    "        else:            \n",
    "            p = [] \n",
    "            for tag in tag_set:\n",
    "                if key == 0:\n",
    "                    transition_p = tags_df.loc['.', tag]\n",
    "                else:\n",
    "                    transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "                emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "                state_probability = emission_p * transition_p    \n",
    "                p.append(state_probability)\n",
    "            \n",
    "            pmax = max(p)\n",
    "            # getting state for which probability is maximum\n",
    "            state_max = tag_set[p.index(pmax)] \n",
    "            state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the viterbi_backedup_by_trigram_tagger is - 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "viterbi_trigram_tagged_seq = viterbi_backedup_by_trigram_tagger(test_tagged_words)\n",
    "\n",
    "# accuracy\n",
    "viterbi_trigram_word_check = [i for i, j in zip(viterbi_trigram_tagged_seq, test_run_base) if i == j]\n",
    "\n",
    "viterbi_trigram_accuracy = len(viterbi_trigram_word_check)/len(viterbi_trigram_tagged_seq)\n",
    "\n",
    "print(\"The accuracy of the viterbi_backedup_by_trigram_tagger is -\", viterbi_trigram_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Test_sentences.txt')\n",
    "text = f.read()\n",
    "sample_test_sent = text.splitlines()\n",
    "f.close()\n",
    "sample_test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of untagged words\n",
    "sample_test_words = [word for sent in sample_test_sent for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq_tst = Viterbi_m2(sample_test_words)\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
